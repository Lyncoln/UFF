---
title: "Trabalho Análise Multivariada"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    highlight: kate
author: "Lyncoln Sousa de Oliveira"
---


```{r knitr_init, echo=FALSE, cache=FALSE, include = FALSE}
options(warn=-1)
library(tidyverse)
library(knitr)
library(rmdformats)

## Global options
options(max.print="75")
opts_chunk$set(echo=FALSE,
	             cache=TRUE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE)
opts_knit$set(width=75)
```

Lendo a base de dados
```{r echo = TRUE}
BD = readr::read_delim("Lyncoln.csv", 
    ";",
    escape_double = FALSE,
    trim_ws = TRUE,
    col_types = cols(grupo = col_character()))
str(BD)
```

# 1.Análise descritiva dos dados

Nesse trabalho será considerado uma base de dados com 800 observações e 18 variáveis, sendo 17 delas questões e 1 o identificador de grupo (grupo1 ou grupo2), cada grupo possui 400 observações. 

Ao analisar a tabela a seguir pode-se observar que os valores médio das questões são maiores para o grupo 2. Ao se observar os valores dos desvios padrões, pode se observar que eles estão muito próximos, o que pode indicar uma igualdade na variância dos grupos.

```{r echo = TRUE}
BD %>% 
  group_by(grupo) %>% 
  summarise_all(list(media = mean,
                     desvio = sd)) %>% 
  knitr::kable()
```

# 2.Análise de Agrupamentos

Serão realizadas análises de agrupamentos por métodos hierárquicos e não hierárquicos. Serão utilizados os seguintes métodos: Ward.D, Single, Centroid e as distâncias euclidian e manhattan.

# 2.1.Análise de Clusters por métodos não hierárquicos

Serão utilizados 2 maneiras de construir clusters, utilizando as distâncias de Euclidean e Manhattan.
Para utilização dos métodos não hierárquico é necessário pré-definir o número de clusters a que serão criados. Para isso, foi utilizado a função Mclust.

```{r echo = TRUE}
require(mclust)
qtd = mclust::Mclust(data = BD[,-18])
qtd$G
```

A função informa que é necessário criar apenas 1 cluster, o que não faz sentido. Como estão sendo analisado 2 grupoz, irão ser feitos 2 clusters.

```{r echo = TRUE}
MVpam = function(distancia, base, qtd){
  pam = cluster::pam(base[,-dim(base)[2]],
                     2,
                     metric = distancia)
  plot(pam$clustering)
  predicao = pam$clustering
  classificacao = xtabs(~ predicao + base$grupo)
  acertos = diag(classificacao)/colSums(classificacao)*100
  return(list("Matriz de confusão" = classificacao,
              "Acertos" = acertos))
}
```


## 2.1.1 Método da distância Euclidiana 

```{r echo = TRUE}
MVpam("euclidean",
      BD, 
      2)
```

## 2.1.2 Método da distância Manhattan

```{r echo = TRUE}
MVpam("manhattan",
      BD,
      2)
```


# 2.2. Análise de Clusters por métodos hierárquicos

```{r}
MVcluster = function(metodo, distancia, base, qtd){
  dend = hclust(dist(base[, -dim(base)[2]], distancia), metodo)
  plot(dend, xlab = "", sub = paste0("Método de ",metodo))
  rect.hclust(dend, k = qtd, border = "royalblue")
  predicao = cutree(dend, k = qtd)
  classificacao = xtabs(~predicao + base$grupo)
  acertos = diag(classificacao)/colSums(classificacao) * 100
  return(list("Matriz de confusão" = classificacao,
  "Acertos" = acertos))
}

```

## 2.2.1. Método de Ward.D com distância Euclideana

```{r echo = TRUE}
MVcluster("ward.D",
          "euclidian",
          BD,
          2)
```

## 2.2.2. Método de Ward.D com distância Manhattan

```{r echo = TRUE}
MVcluster("ward.D",
          "manhattan",
          BD,
          2)
```


## 2.2.3. Método de Single com distância Euclideana

```{r echo = TRUE}
MVcluster("single",
          "euclidian",
          BD,
          2)
```
 
## 2.2.4. Método de Single com distância Manhattan

```{r echo = TRUE}
MVcluster("single",
          "manhattan",
          BD,
          2)
```

## 2.2.5. Método de Centroid com distância Euclideana

```{r echo = TRUE}
MVcluster("centroid",
          "euclidian",
          BD,
          2)
```

## 2.2.6. Método de Centroid com distância Manhattan

```{r echo = TRUE}
MVcluster("centroid",
          "manhattan",
          BD,
          2)
```

# 3. Análise de Discriminante e Análise Fatorial

## 3.1 Análise de Discriminante 

Uma das condições requeridas para a relização da análise de descriminante é normalidade. Foi utilizado o método de Shapiro-Wilk e obteve-se :

```{r echo = TRUE}

mvShapiroTest::mvShapiro.Test(as.matrix(BD[,-18]))$p.value

```
Ao nível de significância de 5% aceitamos H0, isso é, acredita-se que há normalidade dos dados.

```{r echo = TRUE}
MVanalis_disc = function(base){
  analise = MASS::lda(as.data.frame(select_if(base, is.numeric)),
                      BD$grupo,
                      CV = TRUE)
  plot(analise$class, col = "purple")
  predicao = analise$class
  classificacao = xtabs(~ predicao + BD$grupo)
  acertos = diag(classificacao)/ colSums(classificacao) * 100
  return(list("Matriz de confusão" = classificacao,
              "Acertos" = acertos))
}
```

```{r echo = TRUE}
MVanalis_disc(BD)
```



## 3.2 Análise Fatorial


```{r echo = TRUE}
analise_fat_1 = factanal(BD[,-18],
                         factors =11,
                         rotation = "varimax",
                         scores = "regression")

analise_fat_1$loadings

escores = analise_fat_1$scores

MVanalis_disc(as.data.frame(escores))
```


## 3.3 Análise Fatorial pelo critério de Kaiser (1958)

```{r echo = TRUE}
fatores = eigen(cor(BD[,-18]))$values; fatores
```

```{r echo = TRUE}
nfatores = length(fatores[fatores >=1])
paste0(nfatores, " fatores são maiores ou iguais a 1")
```

```{r echo = TRUE}
comp_princ = prcomp(BD[,-18])
plot(comp_princ, type = "lines", main = "")
```

```{r echo = TRUE}
analise_fat_2 = factanal(BD[,-18], factors = 4, rotation = "varimax", scores = "regression")

analise_fat_2$loadings

escores2 = analise_fat_2$scores

```

```{r echo = TRUE} 
MVanalis_disc(as.data.frame(escores2))
```

# 4. Conclusões

Após a aplicação de alguns métodos de divisão dos dados em clusters, foi verificado que o método de Análise de Discriminante foi aquele que apresentou melhores resultados que os outros métodos. O método de análise de discriminante após a realização de análise fatorial apresentou um pouco mais de erros na previsão, porém vale ressaltar que neste método utiliza-se menos variáveis e obteve-se acertos de 79.25% de classificação para o grupo1 e 83.75% para o grupo2, o que é considerado ótimo.